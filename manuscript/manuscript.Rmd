---
title: Estimating Uncertainty for Tipping Points with Deep Learning
authors:
  - name: Marcus Lapeyrolerie
    department: Department of Environmental Science, Policy, and Management
    affiliation: University of California, Berkeley
    location: Berkeley, California
    email: mlapeyro@berkeley.edu
  - name: Carl Boettiger
    department: Department of Environmental Science, Policy, and Management
    affiliation: University of California, Berkeley
    location: Berkeley, California
    email: cboettig@berkeley.edu (corresponding author)
abstract: |
  1. Meaningful representations of uncertainty are an essential component of effective ecological forecasting.
  2. Machine learning
  3. We examine scenarios in which stochasticity and non-linearity can lead to extreme uncertainty under common ecological models.  
  4. We show that ..
  
keywords:
  - Time Series
  - Forecasting
  - Machine Learning
  - Artificial Intelligence
  - Tipping points
bibliography: references.bib
nocite: |
    
header-includes:
  - \usepackage{amsmath}
  - \usepackage{amssymb}
#  - \usepackage{lineno}
#  - \usepackage{endfloat}
#  - \linenumbers
  
output: 
  rticles::arxiv_article:
    keep_tex: true
  word_document: default
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE)
library(tidyverse)
library(patchwork)
library(arrow)

bound <- function(x, percentile = 0.975) {
  dplyr::nth(x, percentile * length(x), order_by = x)
}
```



# Introduction

Uncertainty important to forecasting [@Deitze2018] and decision-making [@Schindler2015]

Machine learning is increasingly effective at forecasting, but methods often focus on creation or assessment only of point predictions [@]. 
Because uncertainty can play such an intrinsic role in ecological dynamics [@Boettiger2018; @Coulson2004; @Oveskienen], it is essential that machine learning applications to ecological forecasting are able to address probablistic forecasts adequately.
We evaluate the ability of some of the most promising machine learning methods for probabilistic forecasts relative to traditional statistical and mechanistic approaches applied to several classic models in ecology.

# Materials and Methods

<!-- some more verbose bits about bifurcation models probably belongs in discussion instead -->
We will focus the analysis of several different forecasting scenarios based around two classic models in population ecology: 
Robert May's consumer-resource model [@May1979], and the Nicholson-Bailey parasatoid-host model [@Nicholson1935]. 
While population dynamics models used to inform decision making in fields such as fisheries are often much more complex, these simple models nevertheless exhibit rich nonlinear dynamics thought to be typical in ecological systems [@]. 
These textbook models have been well studied and form the basis of half a century of research in ecology, including much recent work on topics such as resilience and tipping points [] which has had important theoretical and practical management outcomes [@Folke2009; @].
May's model exhibits alternative stable states. 
In this one-dimensional model, transitions between these states can occur due to intrinsic stochasticity, external forcing, or the gradual environmental change that results in a catastrophic saddle-node bifurcation and generates hysteresis. 
The Nicholson-Bailey model is a two species model which contains a Hopf bifurcation, a non-catastrophic bifurcation which either creates or destroys a limit cycle -- a stable oscillatory pattern. 

Assessing the accuracy of forecasting methods in the face of such bifurcation dynamics is particularly important question for ecological systems and global environmental change problems.
Bifurcations represent the kind of non-linear responses complex systems can make as the result of slowly changing parameters (i.e. the 'environment' in which those dynamics take place.)
This can create a particularly challenging forecasting task when such transitions have not been previously observed in the same system, requiring the forecast to anticipate dynamics for which there are no corresponding analogue in the historical data to date. 

No-analog scenarios [@Williams]



We provide fully reproducible coded examples in R and python for performing, scoring, and visualizing each of the forecasts considered here.
After considerable time considering alternative frameworks, we have emphasized those which best met our requirements for performance, ease-of-use, flexibility, and support for the latest probabilistic machine learning models for forecasting. 
Most of our forecasts use the `darts` framework, a sophisticated and well documented python library with support for a wide range of methods.
Our model-based MCMC forecasts use the `greta` framework, an R library that uses python-based `tensorflow` probability to achieve better performance.
While python-based frameworks currently have the edge in performance and access modern ML algorithms, they lag behind in attention to statistical issues such as the computation of strictly proper skill scores (discussed below.) 
Thus our examples of scoring and visualization will rely on a collection of R packages, in particular, `scoringRules` for the efficient calculation of Continuous Ranked Probability Score (CRPS) and logarithmic probability scores for forecast ensembles [@scoringRules].
We expect greater convergence between methods available in R and python in the future, as already illustrated in the example of `greta`.
Complete code for all examples presented here can be found at https://github.com/boettiger-lab/mee_tipping_point_forecasting.


```{r fig.cap="Forecast scenarios. A. a Hopf bifurcation: a stable node develops into a limit cycle. B. The saddle-node bifurcation."}
hopf <- read_csv("../greta/forecasts/simulation=hopf/hopf_increasing.csv.gz")
panelA <- hopf |> filter(type %in% c("historical", "true"), i < 10) |>
  rename(species = variable) |> 
  mutate(species = forcats::fct_recode(species, host = "H", parasitoid = "P")) |>
  ggplot(aes(t, value, group=interaction(species, i, type), col=species)) + 
  geom_line(show.legend = FALSE, alpha = 0.7) + theme_bw()+  scale_color_grey() +
  ggtitle("A. Hopf bifurcation")

sn <- read_csv("../greta/forecasts/simulation=saddle/saddlenode.csv.gz")
panelB <- sn |> filter(type == "historical", i == 1) |>
  bind_rows(filter(sn, type=="true")|>mutate(type="predicted")) |>
  ggplot(aes(t, value, col = type, group=interaction(i,type), lty=type)) +
  geom_path(alpha=0.5, show.legend = FALSE) +
  scale_color_grey(end=0.6) + theme_bw() + 
  ggtitle("B. Saddle-node bifurcation")

stoch <- read_csv("../greta/forecasts/simulation=stochastic/stochastic.csv.gz")
panelC <- stoch |> filter(type == "historical", i == 1) |>
  bind_rows(filter(stoch, type=="true", i < 50) |> mutate(type="predicted")) |>
  ggplot(aes(t, value, col = type, group=interaction(i,type), lty=type)) +
  geom_path(alpha=0.5) + scale_color_grey(end=0.6) + theme_bw() + 
  ggtitle("C. Stochastic transition")


panelA / panelB / panelC

```

## Scenario 1: Hopf Bifurcation

The Nicholson-Bailey model describes a predator-prey dynamic for the relationship of a host species and an obligate parsatiod, orignally used to model the population dynamics of blowflies (_Lucilia cuprina_) [@Nicholson1935; @Nicholson1954a; @Nicholson1954b; @Hastings].
We consider the form which includes density dependence in the host species, and allow for environmental stochasticity,

\begin{align}
H_{t+1} &= H_t \exp \left( r \left(1 - \tfrac{H}{K_t}\right) - c P_t + \eta_{H,t} \right) \\
P_{t+1} &= H_t \exp \left( r \left(1  \tfrac{H}{K_t}\right) \right)  \left(1 -  \exp \left(- c P_t + \eta_{P,t}\right) \right) \\
K_{t+1} &= K_t + \delta
\label{hopf}
\end{align}

Following @Dakos2012, we further allow the carrying capacity of the host, $K$ to slowly increase at linear rate, which drives a Hopf bifurcation as $K$ becomes sufficiently large. 
In a Hopf bifurcation, a stable node starts an oscillatory pattern which continues to grow in amplitude as the bifurcation parameter continues to increase.
This example illustrates one of the many kinds of challenges which nonlinear phenomena pose to forecasting: the "historical" data prior to the bifurcation never exhibit the cyclical dynamics of growing amplitude that will emerge after the bifurcation occurs.
If we had used a purely deterministic model, the dynamics would be constrained to a single stable point, corresponding to a slowly changing steady-state population size of host and parasitoid populations.
However, stochasticity in this case acts as a source of some additional information about the dynamics, as the noise excites quasi-cycles which are visible in the irregular oscillations that appear significantly prior to the emergence of true limit cycles which follow the bifurcation [@Boettiger2018].


## Scenario 2: The saddle-node bifurcation

A yet more difficult forecasting scenario is created by the saddle-node bifurcation.
May's consumer-resource model is a one-dimensional model describing the growth of a 'resource' population (e.g. herbivore) which is grazed by a consumer [@May1979].
As in the Nicholson-Bailey model, in the absence of that predation the resource population density grows under a density-dependent pattern described by a logistic function.
The resource population is also grazed by a consumer at a rate given by a Holling type III s-curve (typically used to model handling time). 
For a certain range of parameter choices, this model supports alternative stable state dynamics, and this model has been identified and employed in explaining alternative stable state dynamics in a broad range of ecological and socio-ecological systems [@Scheffer2001].  

\begin{align}
N_{t+1} &= N_t + r N_t \left(1 - \frac{N_t}{K} \right) - \frac{h_t N_t^2}{s^2 + N_t^2} + \eta_t \\
h_{t+1} &= h_t + \alpha \\
\eta_t &\sim \mathcal{N}(0, \sigma)
\end{align}

If the environment slowly alters one of the parameters (say, the encounter efficiency, `h_t`, in our formulation), one of the stable nodes moves closer and closer to the unstable saddle point, leading to a bifurcation that destroys the stable state, leaving the system to suddenly transition to the alternative stable state.
Saddle-node bifurcations (also known as fold bifurcations) also create a phenomenon known as hysteresis, where it is not sufficient to restore the environment to the previous parameter values to recover the previous state. 
Unlike the Hopf bifurcation which exhibits a continuous transition from a stable node to a small limit cycle that then grows, the saddle-node transition is a discontinuous or so-called 'catastrophic' bifurcation.
Due both to this sudden, catastrophic nature of the transition and the difficulty in reversing the shift after it has occurred, saddle-node bifurcations have been the subject of intense study.
Tipping point dynamics have long been identified as an important but difficult challenge for forecasting [e.g. @Scheffer2001]. 
Much effort in the ecological literature so far has focused on identifying any 'early warning signs' that a catastrophic bifurcation might occur at all [@Scheffer2009; @Scheffer2012] rather than more ambitious attempts to provide quantitative probabilistic forecasts of the likely distribution of waiting times before such a transition occurs.
Tipping points resulting from Saddle-node bifurcations have been demonstrated in examples ranging from laboratory microcosms [@Dei2011; @Dei2012] to whole-ecosystem experiments [@Carpenter2011], and postulated as a model for global change [@Barnosky2014]. 


## Scenario 3: The stochastic transition

Perhaps the most difficult of all events to predict are those in which large transitions are predominately driven by a random component. 
An example of such a transition event is possible to observe in May's consumer-resource model, in which a stochastic term occasionally results in a transition between alternative stable states.
In such cases, no forecast can precisely predict when a transition will occur, but it is nonetheless possible to deduce the correct distribution of waiting times knowing the correct model. 
In the case of small noise, transitions are Poisson distributed, such that the distribution of waiting times is roughly exponential [e.g. @vanKampen], though post-hoc the trajectories of such transitions can be mistaken for saddle-node transitions [@prosectorsfallacy].
To consider such cases, we will again use May's alternative stable state model, though this time leaving all parameters fixed.  

In this context, predicting the probability of a transition in the future based solely on observations prior to a transition occurring is essentially impossible without additional information constraining the model estimate, as such data is equally consistent with infinitely many models or parameter choices which share the same local linearization about the stable point.  
Unlike the saddle-node bifurcation, there is no slowly warping potential basin which can be detected to inform estimates. 
Thus, in this scenario, rather than considering the problem of predicting the future evolution of a single time series based only on it's historical values, we consider an alternative framing of the task:
we imagine our forecaster has access to historical data from one or more comparable systems which includes a previous stochastic transition event.
Based on this data, our forecaster seeks to identify the distribution of expected transition times for analagous systems starting from the same initial condition. 
This parallels actual practice in which researchers would draw on previous examples of stochastic transitions in a system - lake-ecosystem shifts, disease emergence, changing fire regimes, [].
(Note that such stochastic transitions between alternative stable states can also create oscillatory-like dynamics when stochasticity is sufficiently high enough to drive repeated transitions from one attractor to the other and back again.  In such cases, it might be reasonable to estimate a strictly forward-looking forecast of a single system, predicting the distribution of these transitions.)


## Method group 1: Markov Chain Monte Carlo

As a reference case, we consider the forecast produced by an MCMC estimate of model parameters, _given the true model_.
This represents an idealized case where the nature of the underlying process is known precisely.
Uncertainty comes from parameter estimates and intrinsic stochasticity specified in the model, but does not reflect any uncertainty in our knowledge of the model structure. 
Alternative model structures, even when capable of producing the same nonlinear phenomena (i.e. the same bifurcations) will give very different forecasts. 
Even alternative prior distributions of the parameters will generally yield alternate forecasts, as likelihood ridges are common to nonlinear models.
Thus, this case represents a theoretical upper bound for the performance of forecasts by techniques which do not make such strong assumptions about the underlying processes.


## Method group 2: Statistical models (ARIMA)

<!-- Key distinction here from MCMC above is not on how model parameters are estimated, but rather on approaches that aren't making strong mechanistic assumptions about process, but are merely phenomonological type models
-->

We present forecasts produced by ARIMA models as the model-free analogs to the forecasts made using parameter estimation with MCMC.
Since ARIMA models make the assumption that the future will resemble the past via ARIMA's auto-regressive and moving average components [@cite], these models are not well-suited for problems with complex bifurcation dyanmics.
Thus, ARIMA-based forecasts should be treated as a lower bound for the performance of non-mechanistic models.
In contrast to inference with MCMC, uncertainty with ARIMA models is estimated directly from the learned parameters [@cite].
Since ARIMA is a very commonly encountered forecasting method, we will refer readers to [@cite] for further discussion.


## Method group 3: Machine Learning models

Over the past decade, deep learning has become very popular for a broad range of challenging time series prediction problems [@makridakis].
Deep learning models are often used to make point forecasts, yet for their application to ecological time series, it will often be necessary to use multi-step, probablisitic forecasts. 
For all the deep learning models in this study, we use the same method for uncertainty estimation:
each model is trained to learn the parameters of a Poisson distribution to maximize the log likelihood. 
To compute uncertainty intervals, we draw samples from the learned distribution at each time step and report the 95% confidence interval.

A major nuisance with deep learning methods is their instability to hyperparameters and initialization seeds [@cite].
We found that for the same set of hyperparameters, we could produce starkly different forecasts if we trained two models with different initialization seeds [@figure_].
One explanation for this instability is that machine learning models often get stuck on the local optima of loss surfaces [@modelstability]. 
Another likely cause is that machine learning models commonly overfit the training data [@ying].
Across deep learning, overfitting is a fundamental issue, arising from neural networks being highly overparameterized. 
With so many parameters, deep learning models tend to have high variance and thus overfit the training data, a consequence of the bias-variance trade-off common across statistics and machine learning [@ying].
One frequently cited method to reduce overfitting is K-fold cross validation, but this approach cannot be effectively employed when there is one or few time series in the training set.
To remedy the instability problem, we use an ensemble model, wherein each ML forecast is the union of forecasts from 5 individual models that were trained with different initialization seeds.
We found this simple ensemble method to be an effective way to improve generalizability in the limited data regime.

Recently, it has become established that using memory or attention-based neural networks, and an encoder-decoder architecture is crucial for improving forecasting performance on time series data [@kao, @lyu, @du].
Herein we will provide some background on what these machine learning methods are and their benefits.

### Recurrent Neural Networks

Recurrent neural networks are the predominant memory-based ML method.
Recurrent neural networks differ from feed-forward neural networks in that a recurrent neural network provides feedback to itself between time steps [@sherstinsky].
By providing self-feedback, recurrent neural networks are able to retain information from previous time steps and thus are considered a memory-based method.
However, a standard recurrent neural network is unwieldy to train because of the vanishing and exploding gradient problem [@Pascanu], so there have been specialized neural network architectures designed to avoid these gradient problems.
Long Short-term Memory and Gated Recurrent Units Networks are considered to be the state of the art recurrent neural networks that address exploding and vanishing gradients [@chung].
These methods avoid gradient problems by regulating the self-feedback between time steps via gates which perform operations on the feedback signal -- see @chung for more details.
While GRU's and LSTM's commonly outperform standard RNN's, it is difficult to anticipate whether GRU's or LSTM's will be best suited for any time series problem [@chung], so we investigate both methods.

### Transformers

The Transformer is a state of the art ML architecture that is able to model long and short term dependencies on sequence to sequence tasks [@vaswani].
Transformers use a mechanism called self-attention which interrelates different positions of the input sequence in order to find an informative representation of the input sequence [@vaswani].
For example, if given a sentence, a transformer could learn the contextual relationship between a subject and a direct object, but a recurrent network would process all the words as one phrase.
Because of self-attention, Transformers do not need to process data sequentially, and thus can be parallelized, offering significant computational advantages [@vaswani].
The Transformer is likely to be a foundational method for future AI research [@bommasani], so we considered it critical to investigate Transformers in this study.

### Encoder-Decoder

Encoder-decoder architectures have been shown empirically to excel on sequence to sequence tasks [@learningphrase, @cite, @cite].
Encoder-decoders work by processing the input sequence into a fixed-length vector then decoding the fixed-length vector to the predicted output sequence.
It is thought that by encoding the input sequence to a vector, encoder-decoders find informative representations of the input sequence that make the prediction task easier for the decoder [@sutskever].
Of the models that we present, Block RNNs and Transformers are the only models that use encoder-decoders.


<!--
Basic typology of machine learning methods, how we distinguish "ML" from statistical methods (i.e. bias-variance tradeoff; no criteria to prove that the algorithm produces an unbiased estimate of a given summary statistic)

Stuff about how most machine learning techniques provide only point forecasts
-->

## Forecast skill: strictly proper scores

To compare forecasts, we focus exclusively on metrics of forecast skill which satisfy @Gneiting2007's property of a strictly proper score.
This ensures the very desirable behavior that which no probabilistic forecast $Q(x,t)$ can have a score as high as that of the true process $P(x,t)$ on average. 
In other words, while it is possible for any of the models considered to _overfit_ the data against which they are trained, i.e. have a higher likelihood than the true process, it is not possible for these models to overfit the data against which they are scored.
It is worth noting that this property applies specifically to probabilistic forecasts and not point forecasts. Not all common metrics metrics often used to compare forecasts are strictly proper -- such as the average root-mean-square error or the average absolute error. <!-- MFL: hmm I am not completely following this point here. CB: added some examples of non-strictly-proper scoring metrics. For instance, {darts} has a whole 'metrics' class, which does not include any strictly proper metrics (because ML researchers don't care about statistical theorems?) -->
Concerns about over-fitting arise in most types of model estimation and are a particularly acute concern to machine learning methods due to the bias-variance trade-off [@Mehta2019]. <!-- MFL: I don't think I nailed the overfitting part in ML section but we probably want to reference this here-->
This makes the use of strictly proper scoring especially relevant in assessing machine learning predictions.

Not even all strictly proper scores will agree on the same relative ranking between forecasts.
We will focus on two of the most common such skill metrics, CRPS score and logs score [e.g. see @scoringRules; @Gneiting2014].
Of the two, the logs probability score puts a much a greater penalty on unexpected observations than CRPS, and may be more suitable when the occurrence of unexpected events incurs a particularly high cost.

# Results

We examine forecast skill for each of the six forecasting methods (MCMC, ARIMA, block-RNN, GRU, LSTM, and transformer) in each of our three scenarios (Hopf bifucation, saddle-node bifurcation, stochastic transition).
Using model-based simulations allows us to examine performance against an ensemble of replicates of the "true" process, which further helps identify differences that may occur solely due to chance. 


By taking the true model structure as given, MCMC methods can be used to determine a theoretical limit of forecasting skill.
Note that observations are constrained to a smaller region of state space (i.e. a smaller range of population sizes) than will be realized in future. 
This no-analog aspect of forecasting bifurcation dynamics means that even with many sample points in the training data _and_ perfect knowledge of the true model structure, posterior distributions of parameter values are still influenced by the choice of priors. 


```{r}

forecasts <- read_parquet("data/forecasts.parquet") |> filter(forecasting_model != "ml_ensemble")
observations <- read_parquet("data/observations.parquet")

hopf_obs <- observations |> mutate(variable = as.character(variable)) |> filter(iter %in% 1:15, simulation == "hopf", variable !="X")
saddle_obs <- observations |> filter(iter %in% 1:15, simulation == "saddle")
stochastic_obs <- observations |> filter(iter %in% 1:15, simulation == "stochastic")

```

```{r fig.cap="Forecasts of the Hopf bifurcation under each model"}
forecasts  |> 
  filter(iter %in% 1:15, simulation == "hopf", variable !="X") |> 
  ggplot(aes(x=t, y=value, group = interaction(iter, variable), col=type)) + 
  geom_line(alpha=0.1, data = hopf_obs) +
  geom_line(alpha=0.1) +
  geom_line(data = filter(hopf_obs, type=="historical")) +
  facet_grid(forecasting_model ~ variable, scales = "free") +
  theme_bw()  + 
  coord_cartesian(ylim = c(0,15), xlim=c(75, 200)) + 
  ggtitle("Hopf bifurcation")
```

```{r}

forecasts |> 
  filter(iter %in% 1:15, simulation == "saddle") |> 
  ggplot(aes(x=t, y=value, group = interaction(iter, variable), col=type)) + 
  geom_line(alpha=0.1, data = saddle_obs) +
  geom_line(alpha=0.1) +
  geom_line(data = filter(saddle_obs, type=="historical")) +
  facet_wrap(~forecasting_model, scales = "free") +
  theme_bw()  + coord_cartesian(ylim = c(0,1)) + 
  ggtitle("Saddle-Node bifurcation")
```

```{r}

forecasts |>
  filter(iter %in% 1:15, simulation == "stochastic") |> 
  ggplot(aes(x=t, y=value, group = interaction(iter, variable), col=type)) + 
  geom_line(alpha=0.2, data = filter(stochastic_obs, type=="observed")) +
  geom_line(alpha=0.2) +
  geom_line(data = filter(stochastic_obs, type=="historical")) +
  facet_wrap(~forecasting_model, scales = "free") +
  theme_bw()  + coord_cartesian(ylim = c(0,0.8)) + 
  ggtitle("Stochastic transition")
```




```{r}
scores <- arrow::open_dataset("../scores", format="csv") |> collect()

# shift logs score to strictly positive, non-infinite values so we can use a log-scale
shift <- scores |> 
  filter(!is.infinite(logs)) |> 
  mutate(logs = logs - min(logs) +.01) |>
  pivot_longer(c(logs, crps), 
               names_to = "metric", 
               values_to = "score")
```


```{r}
shift |> 
  ggplot(aes(forecasting_model, score, color=forecasting_model)) + 
  geom_jitter(alpha = 0.06, show.legend = FALSE, shape=".") + 
  coord_flip() +
  facet_grid(simulation ~ metric, scales = "free") + 
  scale_y_log10() +
  theme_bw()

```

```{r}
shift |> 
  group_by(simulation,forecasting_model, metric) |> 
  mutate(t = t - min(t)) |> ungroup() |> 
  filter(metric == "crps", t<100) |> 
  ggplot(aes(t, score, col = forecasting_model, fill=forecasting_model)) + 
  geom_line(aes(group=iter), alpha = 0.05, show.legend=FALSE) +
  facet_grid(simulation ~ forecasting_model, scales="free") + 
  theme_bw() 
```

```{r}
shift |> 
  group_by(simulation,forecasting_model, metric) |> 
  mutate(t = t - min(t)) |> ungroup() |> 
  filter(metric == "logs", t<100) |> 
  ggplot(aes(t, score, col = forecasting_model, fill=forecasting_model)) + 
  geom_line(aes(group=iter), alpha = 0.05, show.legend=FALSE) +
  facet_grid(simulation ~ forecasting_model, scales="free") + 
  theme_bw() + scale_y_log10()
```


# Discussion

Ecological systems have long been acknowledged as complex, due not only to the immense span of dimension and scale such processes involve, but also the frequency of emergent and non-linear phenomena such as stochastic resonance, including bifurcations, tipping points, and hysteresis examined here.
Calls for increased forecasting efforts from ecologists frequently reference the role of changing climate and other anthropogenic change, which raise the challenge of prediction in no-analog environments, anticipating ecosystem responses to conditions that have not been previously observed [@Clark2001; @Dietze2018].
What methods will be most reliable in the face of such uncertainty?

- overall forecasting bifurcations is difficult, even in the idealized case of ample measurement data and knowing the structural model exactly. 

- ML techniques are mostly bracketed by ARIMA and MCMC as expected (better than arima, worse than estimates using true model), though details vary (can do better than MCMC etc).

- MCMC is most relevant to the saddle-node, which is an especially hard problem for the model-free methods.  block rnn does surprisingly well here all things considered. 

- the stochastic context is in some sense the easiest for  ML/statistical methods, as it is the only case where training data includes the phenomenon of the transition.

- MCMC does not always out-perform ML techniques, particularly in CRPS terms. Log likelihood-based skill score 

- Forecast skill assessment can be challenging. it is essential to pay attention to skill over time. Forecast error is not a smooth function of horizon, nor is it always increasing with longer horizons.

- Examining means and summary statistics of variation (confidence intervals) can be limiting too, obscuring aspects such as bimodally distributed scores.


non-linearity,
We have compared the ability of several cutting edge machine learning approaches for forecasting against statistical and process-based models.

- Ecological forecasting invariably is hard


\pagebreak

# References