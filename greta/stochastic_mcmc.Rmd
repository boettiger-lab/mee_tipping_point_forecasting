---
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse, quietly = TRUE)
library(greta, quietly = TRUE)
library(bayesplot, quietly = TRUE)
source("R/utils.R")
source("R/stochastic.R")
```

```{r}
set.seed(4242)
train_reps <- 1
train_t_max <- 250
test_t_max <- 250
test_reps <- 100
simulate <- simulate_stoch
```

```{r}
train <- purrr::map_dfr(1:train_reps, \(i) simulate(t_max=train_t_max), .id = "i")
test <- purrr::map_dfr(1:test_reps, \(i) simulate(t_max=test_t_max), .id = "i")
```

```{r}
m <- greta_model_stoch(train)
bench::bench_time({                 
  draws <- mmcmc(m, n_samples = 60000, warmup = 50000,
                 chains = 4, verbose = FALSE)
})
```

```{r}
## draw test_reps number of samples
combined <- compare_forecast(draws, train, test, simulate, vars = "N",
                              test_reps, test_t_max) 
write_csv(combined, "data/stochastic.csv.gz")
```

```{r}
scores <-
  rep_scores(combined, "N") |> 
  mutate(scenario="stochastic", 
         model="MCMC", 
         reps = train_reps) 

write_csv(scores, "data/scores_stochastic.csv.gz")

```



```{r}
bayesplot::mcmc_trace(draws)
plot_posteriors(draws, p)
```


```{r}
combined |> 
  group_by(t,type,variable) |> 
  summarise(mean = mean(value), sd = sd(value), .groups = "drop") |> 
 ggplot(aes(t, col=type)) + 
  geom_ribbon(aes(ymin = mean-2*sd, ymax = mean+2*sd, fill=type), alpha=0.5) +
  geom_line(aes(y=mean)) +
  geom_vline(aes(xintercept = train_t_max)) + facet_wrap(~variable, ncol=1)
```


```{r}
single <- 
  combined |> 
  filter(i %in% 1:train_reps) |> 
  ggplot(aes(t, value, col=type, group=interaction(i,type))) + 
    geom_line() +
    geom_vline(aes(xintercept = train_t_max)) + facet_wrap(~variable, ncol=1)
```





